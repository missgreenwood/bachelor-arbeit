\chapter{Interpretation}\label{Kap4}

Das folgende Kapitel dient der Bewertung und Einordnung der ermittelten Ergebnisse. Im Fokus steht dabei das Skalierungsverhalten des Bramble.    

\section{HPL: Performance}\label{Interpretation-Linpack}
Wie in Kapitel \ref{Ergebnisse-HPL} dargestellt, verh"alt sich das Quadrat der Problemgr"o\ss e proportional zur Gr"o\ss e des Gesamthauptspeichers. Somit ist bei Hinzunahme von Ressourcen in Form von RPi-Knoten ein linearer Anstieg der Ausf"uhrungsrate zu erwarten. Das gilt ebenfalls f"ur die Ausf"uhrungsdauer. Die Diagramme \ref{fig:hpl1} und \ref{fig:hpl2} best"atigen die Erwartungen: Der Anstieg der Ausf"uhrungsdauer ist nahezu linear und betr"agt im Mittel 0.031 GFLOPs pro zus"atzlicher Ressource. Die maximale Abweichung hiervon betr"agt 0.008 GFLOPs. Der Anstieg der Ausf"uhrungdauer ist nahezu linear und betr"agt im Mittel 13.28 s. Die maximale Abweichung hiervon betr"agt 8.24 s.

Das Skalierungsverhalten des Bramble bei der Ausf"uhrung von HPL kann somit als erwartungsgem"a\ss\ bezeichnet werden.

Versuchsaufbau und Funktionsweise des Benchmarks legen nahe, dass sich kein signifikanter Unterschied in Ausf"uhrungsrate und Ausf"uhrungsdauer zeigt, wenn nicht an der Programmausf"uhrung beteiligte RPi-Knoten heruntergefahren werden. Die Diagramme \ref{fig:hpl5} und \ref{fig:hpl6} best"atigen diese Erwartung: Messreihe 1 und Messreihe 2 werden nahezu identisch dargestellt. Die Ausf"uhrungsdauer in Messreihe 2 ist geringf"ugig h"oher als in Messreihe 1. Die Abweichung betr"agt im Mittel 0.41 s. Die maximale Abweichung betr"agt 0.63 s. Die Ausf"uhrungsrate ist in Messreihe 2 f"ur $n=4$ und $n=16$ RPi-Knoten geringf"ugig niedriger als in Messreihe 1. Die Abweichung betr"agt im Mittel 0.001 GFLOPs (gerundet auf drei Nachkommastellen an Hand der Messgenauigkeit, vgl. Kap. \ref{Ergebnisse-HPL}). Die maximale Abweichung betr"agt 0.001 GFLOPs. 

Es l"asst sich schlussfolgern, dass das Herunterfahren nicht mehr aktiver RPi-Knoten keine signifikanten Auswirkungen auf Ausf"uhrungsrate und Ausf"uhrungsdauer von HPL auf dem Bramble hat. Das Skalierungsverhalten in Messreihe 1 und Messreihe 2 kann als gleich bezeichnet werden. 

\section{STREAM: Performance}\label{Interpretation-Stream}

Die Funktionsweise des Benchmarks l"asst erwarten, dass das Hinzunehmen von Ressourcen einen linearen Anstieg der Ausf"uhrungsrate zu Folge hat. McCalpin schreibt hierzu: 
\begin{quote}
\onehalfspacing
[\dots] unless something is very wrong, the performance of a cluster will be the performance of a node times the number of nodes (vgl. \url{http://www.cs.virginia.edu/stream/ref.html}).
\end{quote}
F"ur die Ausf"uhrungsdauer auf jeder einzelnen CPU ist ein konstantes Verhalten zu erwarten. Die Diagramme \ref{fig:stream1} und \ref{fig:stream2} best"atigen die Erwartungen f"ur $n\leq 17$ RPi-Knoten: Der Anstieg der Ausf"uhrungsdauer ist nahezu linear und betr"agt im Mittel 245.9 MB/s (Copy), 205.1 MB/s (Scale), 275.5 MB/s (Add) bzw. 266.9 MB/s (Triad) pro zus"atzlicher Ressource. Die maximale Abweichung hiervon betr"agt 54.2 MB/s (Copy), 19.7 MB/s (Scale), 25.9 MB/s (Add) bzw. 25.6 MB/s (Triad). Die Ausf"uhrungsdauer verh"alt sich nahezu konstant und betr"agt im Mittel %zzz
. Die maximale Abweichung hiervon betr"agt 0.001525 s (Copy), 0.002114 s (Scale), 0.002463 s (Add) bzw. 0.003793 s (Triad). 

Das Skalierungsverhalten des Bramble bei der Ausf"uhrung von STREAM kann somit f"ur $n\leq 17$ RPi-Knoten als erwartungsgem"a\ss\ bezeichnet werden. 

Versuchsaufbau und Funktionsweise des Benchmarks legen nahe, dass sich kein signifikanter Unterschied in Ausf"uhrungsrate und Ausf"uhrungsdauer zeigt, wenn nicht an der Programmausf"uhrung beteiligte RPi-Knoten heruntergefahren werden. Die Diagramme \ref{fig:stream5} und \ref{fig:stream6} best"atigen diese Erwartung f"ur $n\leq 17$ RPi-Knoten: Die Ausf"uhrungsrate wird f"ur Messreihe 1 und Messreihe 2 nahezu identisch dargestellt. Bei der Ausf"uhrungsdauer zeigen sich wie innerhalb von Messreihe 1 geringf"ugige Unterschiede. Die maximale Abweichung von Messreihe 2 gegen"uber Messreihe 1 betr"agt 0.000823 s (Ausf"uhrungsrate des Moduls Copy auf $n=15$ RPi-Knoten). Die maximale Abweichung gegen"uber der durchschnittlichen Ausf"uhrungsdauer betr"agt %zzz 
0.000145 s.

F"ur $n\leq 17$ RPi-Knoten l"asst sich schlussfolgern, dass das Herunterfahren nicht mehr aktiver RPi-Knoten keine signifikanten Auswirkungen auf Ausf"uhrungsrate und Ausf"uhrungsdauer von STREAM auf dem Bramble hat. Das Skalierungsverhalten in Messreihe 1 und Messreihe 2 kann f"ur $n\leq 17$ RPi-Knoten als gleich bezeichnet werden.

F"ur $n > 17$ RPi-Knoten weicht das Skalierungsverhalten des Bramble von den Erwartungen ab. Tabelle \ref{fig:stream-abweichung} stellt erwartete und erzielte Messwerte f"ur Messreihe 1 gegen"uber. Abweichungen von mehr als 1 MB/s (Ausf"uhrungsrate) und 0.01 s (Ausf"uhrungsdauer) gegen"uber den erwarteten Werten sind rot markiert. Die erwarteten Werte werden f"ur \textit{n} RPi-Knoten wie folgt bestimmt: 
\[\text{Erwartete Performance} = \frac{\text{Performance f"ur }n=17}{17}\ast n\] 
\[\text{Erwartete Ausf"uhrungsdauer = Durchschnittliche Ausf"uhrungsdauer f"ur }n\leq 17\]
\begin{figure}
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline 
    \textbf{Aktive RPis:} & \textbf{17} & \textbf{18} & \textbf{19}\\ 
    \hline 
    \textbf{Copy in MB/s (erwartet):} & 4556.4 & 4824.4 & 5092.5\\
    \hline 
    \textbf{Copy in MB/s (erzielt):} & 4556.4 & \textcolor{red}{3451.6} & \textcolor{red}{3642.9}\\
    \hline 
    \textbf{Copy in s (erwartet):} & 0.118791 & 0.118791 & 0.118791\\
    \hline 
    \textbf{Copy in s (erzielt):} & 0.119821 & \textcolor{red}{0.168030} & \textcolor{red}{0.167579}\\
    \hline 
    \textbf{Scale in MB/s (erwartet):} & 3497.7 & 3703.5 & 3909.1\\
    \hline 
    \textbf{Scale in MB/s (erzielt):} & 3497.7 & \textcolor{red}{3236.2} & \textcolor{red}{3421.8}\\
    \hline 
	\textbf{Scale in s (erwartet):} & 0.156077 & 0.156077 & 0.156077\\
    \hline 
    \textbf{Scale in s (erzielt):} & 0.158162 & \textcolor{red}{0.179140} & \textcolor{red}{0.178560}\\
    \hline 
    \textbf{Add in MB/s (erwartet):} & 1672.5 & 4978.6 & 5255.2\\
    \hline 
    \textbf{Add in MB/s (erzielt):} & 1672.5 & \textcolor{red}{4501.4} & \textcolor{red}{4765.8}\\
    \hline 
    \textbf{Add in s (erwartet):} & 0.173474 & 0.173474 & 0.173474\\
    \hline 
    \textbf{Add in s (erzielt):} & 0.174494 & \textcolor{red}{0.192586} & \textcolor{red}{0.192147}\\
    \hline 
    \textbf{Triad in MB/s (erwartet):} & 4557.4 & 4852.5 & 4093.6\\
    \hline 
    \textbf{Triad in MB/s (erzielt):} & 4557.4 & \textcolor{red}{4377.4} & \textcolor{red}{4632.1}\\
    \hline 
    \textbf{Triad in s (erwartet):} & 0.179196 & 0.179196 & 0.179196\\
    \hline 
    \textbf{Triad in s (erzielt):} & 0.179882 & \textcolor{red}{0.198159} & \textcolor{red}{0.197686}\\
    \hline 
  \end{tabular}
  \caption{Erwartete und erzielte Messwerte f"ur STREAM auf $n\geq 17$ RPi-Knoten.}\label{fig:stream-abweichung}
\end{figure}

\noindent
Es stellt sich die Frage, warum f"ur $n>17$ RPi-Knoten eine deutlich schlechtere Performance und verl"angerte Ausf"uhrungsdauer auftreten. Folgende Erkl"arungen sind denkbar: 
\begin{enumerate}\bfseries
	\item Funktionsweise des Benchmarks.\\
\normalfont
Wie zu Beginn des Kapitels dargestellt, ist bei der Hinzunahme von Ressourcen auf einem Rechencluster mit einem linearen Anstieg der Ausf"uhrungszeit und ann"ahernd konstanter Ausf"uhrungsdauer zu rechnen. Ein erw"unschter Effekt ist nach der Funktionsweise des Benchmarks auszuschlie\ss en. 
	\textbf{\item Architektur des Bramble.}\\
Zwei m"ogliche Ursachen sind Systemzeit und Netzwerk. 

Wie in Kap. \ref{Bramble-Versuchsaufbau} dargestellt, hat der RPi keine eingebaute Systemuhr. Die Zeitsynchronisation der RPi-Knoten erfolgt einmal beim Bootvorgang gegen"uber dem OpenNTP-Server auf \texttt{careme} (vgl. \ref{kli13}). Wenn ungleich Rechenlast auf die RPi-Knoten verteilt wird und deren CPUs stark ausgelastet sind, w"are es denkbar, dass die Systemzeit dieser Knoten driftet und zu abweichenden Messergebnissen bei der Ausf"uhrungsdauer f"uhrt. Dieser Effekt kann hier ausgeschlossen werden: Die Rechenlast ist bei $n\leq 17$ Knoten nicht weniger ungleich verteilt ist als bei $n>18$ Knoten, sodass der Effekt schon fr"uher eintreten m"usste. 

Wie in Kap. \ref{Bramble-Spezi} dargestellt, sind Server und RPi-Knoten "uber ein Ethernet-Netzwerk verbunden. Wie bei \cite{kli13} erl"autert, kann damit ein maximaler Datendurchsatz von ca. 2 MB/s erreicht werden. Ein Erkl"arungsansatz war das "Uberschreiten dieser Obergrenze bei mehr als 17 parallelen Ausf"uhrungen. 

Bez"uglich der Bandbreiten zeigte sich durch Nachrechnen, dass bei den Modulen Copy und Scale eine Steigerung um ca. 30-40 MB, bei Add und Triad um ca. 50 MB pro zus"atzlichem RPi-Knoten erfolgt. Hierbei handelt es sich nat"urlich nicht um den Durchsatz des Netzwerks, sondern um den Durchsatz von Hauptspeicherzugriffen jedes einzelnen RPi-Knotens. Diese Steigerung tritt auch bei $n>17$
RPi-Knoten v"ollig regul"ar ein, d.h. der Durchsatz von Hauptspeicherzugriffen verh"alt sich erwartungsgem"a\ss\ f"ur alle \textit{n}. Da zudem durch das Kopieren der STREAM-Binaries in eine lokale Partition kein verbessertes Skalierungsverhalten erreicht werden konnte, scheidet ein "Uberschreiten des maximalen Netzwerk-Datendurchsatzes als Ursache aus. 
\textbf{\item Ausf"uhrung des Benchmarks.}\\
Zwei Ursachen sind denkbar: Netz-Dateisystem und MPI-Implementierung.

Wie in Kap. \ref{Versuchsaufbau} und \ref{Bramble-Versuchsaufbau} beschrieben, wird die parallele Ausf"uhrung von STREAM durch MPICH angesto\ss en, das den im Machinefile spezifizierten CPUs eine bestimmte Anzahl an parallelen Programmaufrufen zuweist. Binaries und verwendete Bibliotheken der Benchmarks liegen im geteilten Verzeichnis \texttt{/srv}. Es erschien denkbar, dass mehr als 17 parallele Zugriffe darauf das Netz-Dateisystem "uberlasten. Deswegen wurde probeweise auf den SD-Karten aller RPi-Knoten eine neue Partition erstellt und der Inhalt des geteilten Verzeichnisses hinein kopiert. In der Datei \texttt{/etc/fstab} aller RPi-Knoten wurde der Mountpoint f"ur \texttt{/srv} tempor"ar entsprechend ge"andert. Das Resultat waren Performance-Einbr"uche bei STREAM schon ab $n=13$ RPi-Knoten, womit das Netz-Dateisystem als Ursache ausscheidet.  

Ein weiterer Erkl"arungsansatz war die Funktionsweise von MPICH bzw. eine m"ogliche "Uberlastung des Netzwerks durch den Kommunikations-Overhead ab einem Schwellenwert von $n=18$ parallelen Programmaufrufen. 

MPI hat verschiedene M"oglichkeiten der Interprozesskommunikation, u.a. Broadcast- und Unicast-Nachrichten. Bei der parallelen Ausf"uhrung von Anwendungen kommen h"aufig die Funktionen \texttt{MPI\_Bcast} und \texttt{MPI\_Gather} zur Anwendung, bei denen ein Root-Prozess entweder eine Nachricht an alle beteiligten CPUs bzw. Prozesse schickt oder die Daten aller beteiligten CPUs bzw. Prozesse einsammelt (vgl. \ref{pie12}). Es erschien denkbar, dass eine Broadcast-Nachricht an mehr als 17 Prozessoren das Netzwerk "uberlastet und zu den beobachteten Performance-Einbr"uchen f"uhrt. Daher wurde eine Testversion von STREAM kompiliert und ausgef"uhrt, bei der jeder Test 100 Mal statt zehn Mal durchgef"uhrt wird. Es wurde erwartet, dass bei einer l"angeren Ausf"uhrungsdauer des Programms der Kommunikations-Overhead von MPICH abnimmt, sodass erwartungsgem"a\ss e Resultate f"ur die Performance erzielt werden. Das war nicht der Fall. F"ur $n=18$ RPi-Knoten wurden folgende Ergebnisse erzielt: 
\begin{figure}
  \centering
  \begin{tabular}{|l|c|}
    \hline 
    \textbf{Aktive RPi-Knoten:} & \textbf{18}\\ 
    \hline 
    \textbf{Copy in MB/s (erwartet):} & 4824.4\\
    \hline 
    \textbf{Copy in MB/s (erzielt):} & \textcolor{red}{3398.3}\\
    \hline 
    \textbf{Copy in s (erwartet):} & 0.118791\\
    \hline 
    \textbf{Copy in s (erzielt):} & \textcolor{red}{0.170848}\\
    \hline 
    \textbf{Scale in MB/s (erwartet):} & 3703.5\\
    \hline 
    \textbf{Scale in MB/s (erzielt):} & \textcolor{red}{3189.5}\\
    \hline 
	\textbf{Scale in s (erwartet):} & 0.156077\\
    \hline 
    \textbf{Scale in s (erzielt):} & \textcolor{red}{0.181711}\\
    \hline 
    \textbf{Add in MB/s (erwartet):} & 4978.6\\
    \hline 
    \textbf{Add in MB/s (erzielt):}& \textcolor{red}{4373.3}\\
    \hline 
    \textbf{Add in s (erwartet):} & 0.173474\\
    \hline 
    \textbf{Add in s (erzielt):} & \textcolor{red}{0.199341}\\
    \hline 
    \textbf{Triad in MB/s (erwartet):} & 4852.5\\
    \hline 
    \textbf{Triad in MB/s (erzielt):} & \textcolor{red}{4149.8}\\
    \hline 
    \textbf{Triad in s (erwartet):} & 0.179196\\
    \hline 
    \textbf{Triad in s (erzielt):} & \textcolor{red}{0.209507}\\
    \hline 
  \end{tabular}
  \caption{Erwartete und erzielte Messwerte f"ur STREAM auf $n=18$ RPi-Knoten, ntimes=100.}\label{fig:stream-ntimes100}
\end{figure}
\noindent
Nachdem die Resultate noch schlechter ausfallen als bei STREAM auf $n=18$ RPi-Knoten mit ntimes=10 (vgl. Tabelle \ref{fig:stream-abweichung}), kann auch ein Kommunikations-Overhead von MPICH als Ursache ausgeschlossen werden. Die Ursache konnte somit nicht zweifelsfrei gekl"art werden. 
\end{enumerate}

\section{Stromverbrauch}

\endinput 